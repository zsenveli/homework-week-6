---
title: "Homework06-Zeynep"
author: "Zeynep Senveli"
date: "10/19/2017"
output: html_document
---

# Reading in the Kamilar and Cooper dataset:
```{r}
library(curl)
library(ggplot2)
f <- curl("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN597_Fall17/KamilarAndCooperData.csv")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
head(d)
attach(d)
```
# The regression:
```{r}
attach(d)
regression <- lm(d$MaxLongevity_m ~ d$Brain_Size_Species_Mean, data = d)
regression
summary(regression)
```

# Writing up the regression equation extracting it from the coefficient matrix in the summary to later append on the graph:
```{r}
attach(d)
summary(regression)
intercept <- summary(regression)$coefficients[1,1]
slope <- summary(regression)$coefficients[2,1]
error <- summary(regression)$coefficients[1,2]
x <- NULL
equation <- intercept + slope*x + error
```

# Plotting the regression equation:
```{r}
attach(d)
g <- ggplot(data = d, aes(x = Brain_Size_Species_Mean, y = MaxLongevity_m))
g <- g + geom_point()
g <- g + geom_smooth(method = "lm", formula = y ~ x)
g
```


# Our preditor variable is brain size and our output variable is longevity. For every 1 unit change in brain size, there will be a 1.22 increase in longevity. Looking at my F-statistic to see if I can reject/fail to reject my null hypothesis, and my results are F(1,126)=122.4, p < 2.2e-16, which allows me to very certainly reject null hypothesis because my p value is very significant.

# 90% Confidence Interval:
```{r}
CI <- confint(regression, level = 0.90)
CI
summary(CI)
```
# So my 90% CI tells me that for every 1 unit of increase in brain size, the range of the increase in longevity should fall between 1.03 and 1.40.

# My point estimate for 800mg: 
```{r}
p_estimate = intercept + slope*800 + error
p_estimate
```

# Calculating residuals: 
```{r}
m <- lm(data = d, d$MaxLongevity_m ~ d$Brain_Size_Species_Mean)
h_hat <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean))
df <- data.frame(cbind(d$Brain_Size_Species_Mean, d$MaxLongevity_m, h_hat))
names(df) <- c("Brain Size", "Longevity", "yhat")
head(df)
```


#Setting the prediction interval:
```{r}
pi <- predict(m, newdata = data.frame(Brain_Size_Species_Mean = d$Brain_Size_Species_Mean), interval = "prediction", 
    level = 0.90)
head(pi)
```



# The same process now for log values, starting with assigning the log values to new variables:
```{r}
log_brainsize <- log(d$Brain_Size_Species_Mean)
log_brainsize
log_longevity <- log(d$MaxLongevity_m)
log_longevity
```

# The regression equation for log values:
```{r}
log_regression <- lm(log(d$MaxLongevity_m) ~ log(d$Brain_Size_Species_Mean), data = d)
log_regression
summary(log_regression)
```

# Plotting the graph for log values:
```{r}
attach(d)
g_log <- ggplot(data = d, aes(x = log(d$Brain_Size_Species_Mean), y = log(d$MaxLongevity_m)))
g_log <- g_log + geom_point()
g_log <- g_log + geom_smooth(method = "lm", formula = y ~ x)
g_log
```
```{r}
CI_log <- confint(regression, level = 0.90)
CI_log
summary(CI_log)
```

# Our preditor variable is the log of brain size and our output variable is the log of longevity. For every 1 unit change in log of brain size, there will be a 0.23 increase in longevity. Looking at my F-statistic to see if I can reject/fail to reject my null hypothesis, and my results are F(1,126)=172.9, p < 2.2e-16, which allows me to very certainly reject null hypothesis because my p value is very significant.


# Looking at the two models, the log one is better because the coefficient of determination in the log model is 57% while it is 49% for the first model. This means that the log values of the brain size mean accounts for a greater proportion of the variance we see in the log values of longevity. 